{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-386318c01afa>:55: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From e:\\Anaconda\\envs\\geocomp\\lib\\site-packages\\tensorflow\\python\\training\\input.py:276: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From e:\\Anaconda\\envs\\geocomp\\lib\\site-packages\\tensorflow\\python\\training\\input.py:188: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From e:\\Anaconda\\envs\\geocomp\\lib\\site-packages\\tensorflow\\python\\training\\input.py:197: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From e:\\Anaconda\\envs\\geocomp\\lib\\site-packages\\tensorflow\\python\\training\\input.py:197: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From <ipython-input-6-386318c01afa>:28: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
      "WARNING:tensorflow:From <ipython-input-6-386318c01afa>:79: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimension size must be evenly divisible by 268203 but is 1505280 for 'Reshape_1' (op: 'Reshape') with input shapes: [10,224,224,3], [4] and with input tensors computed as partial shapes: input[1] = [?,299,299,3].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32me:\\Anaconda\\envs\\geocomp\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1627\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1628\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1629\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimension size must be evenly divisible by 268203 but is 1505280 for 'Reshape_1' (op: 'Reshape') with input shapes: [10,224,224,3], [4] and with input tensors computed as partial shapes: input[1] = [?,299,299,3].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-386318c01afa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[1;31m#nanno_train()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m \u001b[0mnanno_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-386318c01afa>\u001b[0m in \u001b[0;36mnanno_eval\u001b[1;34m()\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[0mlabel_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_batch_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_offset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m     \u001b[0mlogits_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnanno_inference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_batch_placeholder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m     \u001b[0mlogits_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_int64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_max\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdimension\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-386318c01afa>\u001b[0m in \u001b[0;36mnanno_inference\u001b[1;34m(image_batch)\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[0mb_conv1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbias_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m     \u001b[0mx_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[0mh_conv1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_conv1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb_conv1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda\\envs\\geocomp\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m   6479\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6480\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m-> 6481\u001b[1;33m         \"Reshape\", tensor=tensor, shape=shape, name=name)\n\u001b[0m\u001b[0;32m   6482\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6483\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda\\envs\\geocomp\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda\\envs\\geocomp\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    486\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m                 instructions)\n\u001b[1;32m--> 488\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    490\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32me:\\Anaconda\\envs\\geocomp\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3272\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3273\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3274\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3275\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3276\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda\\envs\\geocomp\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1790\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1791\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1792\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1794\u001b[0m     \u001b[1;31m# Initialize self._outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda\\envs\\geocomp\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1629\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1630\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1631\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1633\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimension size must be evenly divisible by 268203 but is 1505280 for 'Reshape_1' (op: 'Reshape') with input shapes: [10,224,224,3], [4] and with input tensors computed as partial shapes: input[1] = [?,299,299,3]."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf # tensorflow module\n",
    "import numpy as np # numpy module\n",
    "import os # path join\n",
    "\n",
    "\n",
    "DATA_DIR = r\"C:\\Users\\Dan Austin\\Documents\\GitHub\\Nannotaxi\\resize_image\"\n",
    "TRAINING_SET_SIZE = 300\n",
    "BATCH_SIZE = 10\n",
    "IMAGE_SIZE = 299\n",
    "\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "# image object from protobuf\n",
    "class _image_object:\n",
    "    def __init__(self):\n",
    "        self.image = tf.Variable([], dtype = tf.string)\n",
    "        self.height = tf.Variable([], dtype = tf.int64)\n",
    "        self.width = tf.Variable([], dtype = tf.int64)\n",
    "        self.filename = tf.Variable([], dtype = tf.string)\n",
    "        self.label = tf.Variable([], dtype = tf.int32)\n",
    "\n",
    "def read_and_decode(filename_queue):\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    features = tf.parse_single_example(serialized_example, features = {\n",
    "        \"image/encoded\": tf.FixedLenFeature([], tf.string),\n",
    "        \"image/height\": tf.FixedLenFeature([], tf.int64),\n",
    "        \"image/width\": tf.FixedLenFeature([], tf.int64),\n",
    "        \"image/filename\": tf.FixedLenFeature([], tf.string),\n",
    "        \"image/class/label\": tf.FixedLenFeature([], tf.int64),})\n",
    "    image_encoded = features[\"image/encoded\"]\n",
    "    image_raw = tf.image.decode_jpeg(image_encoded, channels=3)\n",
    "    image_object = _image_object()\n",
    "    image_object.image = tf.image.resize_image_with_crop_or_pad(image_raw, IMAGE_SIZE, IMAGE_SIZE)\n",
    "    image_object.height = features[\"image/height\"]\n",
    "    image_object.width = features[\"image/width\"]\n",
    "    image_object.filename = features[\"image/filename\"]\n",
    "    image_object.label = tf.cast(features[\"image/class/label\"], tf.int64)\n",
    "    return image_object\n",
    "\n",
    "def nanno_input(if_random = True, if_training = True):\n",
    "    if(if_training):\n",
    "        filenames = [os.path.join(r'C:\\Users\\Dan Austin\\Documents\\GitHub\\Nannotaxi', \"train-0000%d-of-00002\" % i) for i in range(0, 1)]\n",
    "    else:\n",
    "        filenames = [os.path.join(r'C:\\Users\\Dan Austin\\Documents\\GitHub\\Nannotaxi', \"validation-0000%d-of-00002\" % i) for i in range(0, 1)]\n",
    "\n",
    "    for f in filenames:\n",
    "        if not tf.gfile.Exists(f):\n",
    "            raise ValueError(\"Failed to find file: \" + f)\n",
    "    filename_queue = tf.train.string_input_producer(filenames)\n",
    "    image_object = read_and_decode(filename_queue)\n",
    "    image = tf.image.per_image_standardization(image_object.image)\n",
    "#    image = image_object.image\n",
    "#    image = tf.image.adjust_gamma(tf.cast(image_object.image, tf.float32), gamma=1, gain=1) # Scale image to (0, 1)\n",
    "    label = image_object.label\n",
    "    filename = image_object.filename\n",
    "\n",
    "    if(if_random):\n",
    "        min_fraction_of_examples_in_queue = 0.4\n",
    "        min_queue_examples = int(TRAINING_SET_SIZE * min_fraction_of_examples_in_queue)\n",
    "        print(\"Filling queue with %d images before starting to train. \" \"This will take a few minutes.\" % min_queue_examples)\n",
    "        num_preprocess_threads = 1\n",
    "        image_batch, label_batch, filename_batch = tf.train.shuffle_batch(\n",
    "            [image, label, filename],\n",
    "            batch_size = BATCH_SIZE,\n",
    "            num_threads = num_preprocess_threads,\n",
    "            capacity = min_queue_examples + 3 * BATCH_SIZE,\n",
    "            min_after_dequeue = min_queue_examples)\n",
    "        return image_batch, label_batch, filename_batch\n",
    "    else:\n",
    "        image_batch, label_batch, filename_batch = tf.train.batch(\n",
    "            [image, label, filename],\n",
    "            batch_size = BATCH_SIZE,\n",
    "            num_threads = 1)\n",
    "        return image_batch, label_batch, filename_batch\n",
    "\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.05)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.02, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def nanno_inference(image_batch):\n",
    "    W_conv1 = weight_variable([5, 5, 3, 32])\n",
    "    b_conv1 = bias_variable([32])\n",
    "\n",
    "    x_image = tf.reshape(image_batch, [-1, IMAGE_SIZE, IMAGE_SIZE, 3])\n",
    "\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "    h_pool1 = max_pool_2x2(h_conv1) # 112\n",
    "\n",
    "    W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "    b_conv2 = bias_variable([64])\n",
    "\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "    h_pool2 = max_pool_2x2(h_conv2) # 56\n",
    "\n",
    "    W_conv3 = weight_variable([5, 5, 64, 128])\n",
    "    b_conv3 = bias_variable([128])\n",
    "\n",
    "    h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)\n",
    "    h_pool3 = max_pool_2x2(h_conv3) # 28\n",
    "\n",
    "    W_conv4 = weight_variable([5, 5, 128, 256])\n",
    "    b_conv4 = bias_variable([256])\n",
    "\n",
    "    h_conv4 = tf.nn.relu(conv2d(h_pool3, W_conv4) + b_conv4)\n",
    "    h_pool4 = max_pool_2x2(h_conv4) # 14\n",
    "\n",
    "    W_conv5 = weight_variable([5, 5, 256, 256])\n",
    "    b_conv5 = bias_variable([256])\n",
    "\n",
    "    h_conv5 = tf.nn.relu(conv2d(h_pool4, W_conv5) + b_conv5)\n",
    "    h_pool5 = max_pool_2x2(h_conv5) # 7\n",
    "\n",
    "    W_fc1 = weight_variable([7*7*256, 2048])\n",
    "    b_fc1 = bias_variable([2048])\n",
    "\n",
    "    h_pool5_flat = tf.reshape(h_pool5, [-1, 7*7*256])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool5_flat, W_fc1) + b_fc1)\n",
    "\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, 1.0)\n",
    "\n",
    "    W_fc2 = weight_variable([2048, 256])\n",
    "    b_fc2 = bias_variable([256])\n",
    "\n",
    "    h_fc2 = tf.nn.relu(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "    W_fc3 = weight_variable([256, 64])\n",
    "    b_fc3 = bias_variable([64])\n",
    "\n",
    "    h_fc3 = tf.nn.relu(tf.matmul(h_fc2, W_fc3) + b_fc3)\n",
    "\n",
    "    W_fc4 = weight_variable([64, 5])\n",
    "    b_fc4 = bias_variable([5])\n",
    "\n",
    "    y_conv = tf.nn.softmax(tf.matmul(h_fc3, W_fc4) + b_fc4)\n",
    "#    y_conv = tf.matmul(h_fc3, W_fc4) + b_fc4\n",
    "\n",
    "    return y_conv\n",
    "\n",
    "\n",
    "def nanno_train():\n",
    "    image_batch_out, label_batch_out, filename_batch = nanno_input(if_random = False, if_training = True)\n",
    "\n",
    "    image_batch_placeholder = tf.placeholder(tf.float32, shape=[BATCH_SIZE, 224, 224, 3])\n",
    "    image_batch = tf.reshape(image_batch_out, (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "    label_batch_placeholder = tf.placeholder(tf.float32, shape=[BATCH_SIZE, 5])\n",
    "    label_offset = -tf.ones([BATCH_SIZE], dtype=tf.int64, name=\"label_batch_offset\")\n",
    "    label_batch_one_hot = tf.one_hot(tf.add(label_batch_out, label_offset), depth=5, on_value=1.0, off_value=0.0)\n",
    "\n",
    "    logits_out = nanno_inference(image_batch_placeholder)\n",
    "#    loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels=label_batch_one_hot, logits=logits_out))\n",
    "    loss = tf.losses.mean_squared_error(labels=label_batch_placeholder, predictions=logits_out)\n",
    "\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.0005).minimize(loss)\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        # Visualize the graph through tensorboard.\n",
    "        file_writer = tf.summary.FileWriter(\"./logs\", sess.graph)\n",
    "\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        saver.restore(sess, r\"C:\\Users\\Dan Austin\\Documents\\GitHub\\Nannotaxi\\checkpoint-train.ckpt\")\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord, sess = sess)\n",
    "\n",
    "        for i in range(TRAINING_SET_SIZE * 100):\n",
    "            image_out, label_out, label_batch_one_hot_out, filename_out = sess.run([image_batch, label_batch_out, label_batch_one_hot, filename_batch])\n",
    "\n",
    "            _, infer_out, loss_out = sess.run([train_step, logits_out, loss], feed_dict={image_batch_placeholder: image_out, label_batch_placeholder: label_batch_one_hot_out})\n",
    "\n",
    "            print(i)\n",
    "            print(image_out.shape)\n",
    "            print(\"label_out: \")\n",
    "            print(filename_out)\n",
    "            print(label_out)\n",
    "            print(label_batch_one_hot_out)\n",
    "            print(\"infer_out: \")\n",
    "            print(infer_out)\n",
    "            print(\"loss: \")\n",
    "            print(loss_out)\n",
    "            if(i%50 == 0):\n",
    "                saver.save(sess, r\"C:\\Users\\Dan Austin\\Documents\\GitHub\\Nannotaxi\\checkpoint-train.ckpt\")\n",
    "\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        sess.close()\n",
    "\n",
    "\n",
    "\n",
    "def nanno_eval():\n",
    "    image_batch_out, label_batch_out, filename_batch = nanno_input(if_random = False, if_training = False)\n",
    "\n",
    "    image_batch_placeholder = tf.placeholder(tf.float32, shape=[BATCH_SIZE, 224, 224, 3])\n",
    "    image_batch = tf.reshape(image_batch_out, (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "    label_tensor_placeholder = tf.placeholder(tf.int64, shape=[BATCH_SIZE])\n",
    "    label_offset = -tf.ones([BATCH_SIZE], dtype=tf.int64, name=\"label_batch_offset\")\n",
    "    label_batch = tf.add(label_batch_out, label_offset)\n",
    "\n",
    "    logits_out = tf.reshape(nanno_inference(image_batch_placeholder), [BATCH_SIZE, 5])\n",
    "    logits_batch = tf.to_int64(tf.arg_max(logits_out, dimension = 1))\n",
    "\n",
    "    correct_prediction = tf.equal(logits_batch, label_tensor_placeholder)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        saver.restore(sess, \"/home/yeephycho/github/tensorflow_tutorial/tf-cnn/src/checkpoint-train.ckpt\")\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord, sess = sess)\n",
    "\n",
    "        accuracy_accu = 0\n",
    "\n",
    "        for i in range(29):\n",
    "            image_out, label_out, filename_out = sess.run([image_batch, label_batch, filename_batch])\n",
    "\n",
    "            accuracy_out, logits_batch_out = sess.run([accuracy, logits_batch], feed_dict={image_batch_placeholder: image_out, label_tensor_placeholder: label_out})\n",
    "            accuracy_accu += accuracy_out\n",
    "\n",
    "            print(i)\n",
    "            print(image_out.shape)\n",
    "            print(\"label_out: \")\n",
    "            print(filename_out)\n",
    "            print(label_out)\n",
    "            print(logits_batch_out)\n",
    "\n",
    "        print(\"Accuracy: \")\n",
    "        print(accuracy_accu / 29)\n",
    "\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        sess.close()\n",
    "\n",
    "#nanno_train()\n",
    "nanno_eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geocomp",
   "language": "python",
   "name": "geocomp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
